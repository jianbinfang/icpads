\section{Experimental Setup \label{sec:setup}}
<<<<<<< HEAD
NVIDIA Jetson TX2 is NVIDIA¡¯s second-generation CUDA-capable
edge device. TX2 runs
Linux using a quad-core ARM CPU. It is equipped with
an NVIDIA Pascal GPU, which contains specialized
architecture for AI applications. TX2 has 8 GB of LPDDR4
RAM and supports PCIe2.0 and various peripherals such
as UART, GPIOs, HDMI, USB 3.0 and 2.0, Ethernet, and
802.11ac WLAN. NVIDIA provides the required drivers and
CUDA toolkits for TX2 via the JetPack SDK.
=======
\subsection{Platform and Models}
%Describe hardware
\cparagraph{Hardware.} Our experimental platform is the NVIDIA Jetson TX2 embedded deep learning platform. The system has a 64~bit
dual-core Denver2 and a 64~bit quad-core ARM Cortex-A57 running at 2.0~Ghz, and a 256-core NVIDIA Pascal GPU running at 1.3~Ghz. The board
has 8~GB of LPDDR4 RAM and 96~GB of storage (32~GB eMMC plus 64~GB SD card).


%Describe software
\cparagraph{System Software.} Our evaluation platform runs Ubuntu 16.04 with Linux kernel v4.4.15. We use Tensorflow v.1.0.1, cuDNN (v6.0)
and CUDA (v8.0.64).


\cparagraph{Deep Learning Models.} We consider \FIXME{14} pre-trained \CNN models for image recognition from the TensorFlow-Slim
library~\cite{silberman2013tensorflow}. The models are built using TensorFlow and trained on the ImageNet ILSVRC 2012 training set.


\subsection{Evaluation Methodology \label{sec:method}}


\cparagraph{Evaluation Metrics} We consider the following metrics:

%\vspace{-2mm}
\begin{itemize}
\item \emph{\textbf{Inference time} (lower is better)}. Wall clock time between a model taking in an input and producing an output,
    excluding the model load time.

\item \emph{\textbf{Energy consumption} (lower is better)}. The energy used by a model for inference.  We deduct the static power used by
    the hardware when the system is idle.

\item \emph{\textbf{Accuracy} (higher is better)}. The ratio of correctly labeled images to the total number of testing images.

\item \emph{\textbf{Precision} (higher is better)}. The ratio of a correctly predicted images to the total number of images that are
    predicted to have a specific object. This metric answers e.g., ``\emph{Of all the images that are labeled to have a cat, how many
    actually have a cat?}".

\item \emph{\textbf{Recall} (higher is better)}. The ratio of correctly predicted images to the total number of test images that belong
    to an object class. This metric answers e.g., ``\emph{Of all the test images that have a cat, how many are actually labeled to have a
    cat?}".

\item \emph{\textbf{F1 score} (higher is better)}.  The weighted average of Precision and Recall, calculated as $2\times\frac{Recall
    \times Precision} {Recall + Precision}$. It is useful when the test datasets have an uneven distribution of object classes.

\end{itemize}

\cparagraph{Performance Report.}  To collect inference time and energy consumption, we run each model on each input repeatedly until the
95\% confidence bound per model per input is smaller than 5\%. In the experiments, we exclude the loading time of the \CNN models as they
only need to be loaded once in practice. To measure energy consumption, we developed a lightweight runtime to take readings from the
on-board energy sensors at a frequency of 1,000 samples per second. We then matched the energy readings against the time stamps of model
execution to calculate the energy consumption.
>>>>>>> 855a741c7f38a556ddbfc0133f6bd1a25d67cea3

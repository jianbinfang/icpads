\section{Experimental Setup \label{sec:setup}}
\subsection{Platform and Models\label{sec:platform}}
%Describe hardware
\cparagraph{Hardware.} Our experimental platform is a NVIDIA Jetson TX2 embedded platform. The system has a 64~bit dual-core Denver2 and a
64~bit quad-core ARM Cortex-A57 running at 2.0~Ghz, and a 256-core NVIDIA Pascal GPU running at 1.3~Ghz. The board has 8~GB of LPDDR4 RAM
and 96~GB of storage (32~GB eMMC plus 64~GB SD card).


%Describe software
\cparagraph{System Software.} We run the Ubuntu 16.04 operating system with Linux kernel v4.4.15. We use Tensorflow v.1.6, cuDNN (v6.0) and
CUDA (v8.0.64).


\cparagraph{Deep Learning Models.} We consider \FIXME{14} pre-trained \CNN models for image recognition from the TensorFlow-Slim
library~\cite{silberman2013tensorflow}. The models are built using TensorFlow and trained on the ImageNet ILSVRC 2012 training set.


\subsection{Evaluation Methodology \label{sec:method}}


\cparagraph{Evaluation Metrics} We consider the following metrics:

%\vspace{-2mm}
\begin{itemize}
\item \emph{\textbf{Inference time} (lower is better)}. Wall clock time between a model taking in an input and producing an output,
    excluding the model load time.

\item \emph{\textbf{Energy consumption} (lower is better)}. The energy used by a model for inference.  We deduct the static power used by
    the hardware when the system is idle.

\item \emph{\textbf{Accuracy} (higher is better)}. The ratio of correctly labeled images to the total number of testing images.

\item \emph{\textbf{Precision} (higher is better)}. The ratio of a correctly predicted images to the total number of images that are
    predicted to have a specific object. This metric answers e.g., ``\emph{Of all the images that are labeled to have a cat, how many
    actually have a cat?}".

\item \emph{\textbf{Recall} (higher is better)}. The ratio of correctly predicted images to the total number of test images that belong
    to an object class. This metric answers e.g., ``\emph{Of all the test images that have a cat, how many are actually labeled to have a
    cat?}".

\item \emph{\textbf{F1 score} (higher is better)}.  The weighted average of Precision and Recall, calculated as $2\times\frac{Recall
    \times Precision} {Recall + Precision}$. It is useful when the test datasets have an uneven distribution of object classes.

\item \emph{\textbf{BLUE}} {higher is better}. \FIXME{Explain blue here!}

\end{itemize}

\cparagraph{Performance Report.}  To collect inference time and energy consumption, we run each model on each input repeatedly until the
95\% confidence bound per model per input is smaller than 5\%. In the experiments, we exclude the loading time of the \CNN models as they
only need to be loaded once in practice. To measure energy consumption, we developed a lightweight runtime to take readings from the
on-board energy sensors at a frequency of 1,000 samples per second. We then matched the energy readings against the time stamps of model
execution to calculate the energy consumption.

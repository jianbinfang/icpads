\begin{figure}[t!]
\centering
\includegraphics[width=0.35\textwidth]{figure/performance2oracle.pdf}
\caption{Our performance w.r.t. performance of an oracle predictor. We
achieve over 80\% of the oracle performance.}
\label{fig:performance2oracle}
\vspace{-4mm}
\end{figure}



\section{Experimental Results}
In this section, we first compare our approach against WS and the Linux interactive governor. We then evaluate our approach against an ideal predictor,
showing that our approach delivers over 80\% of the oracle performance.
Finally, we analyze the working mechanism of our
approach.

\subsection{Overall Results\label{sec:overall_result}}

Figure~\ref{fig:overall} shows the performance results of our approach and
WS for the three evaluation metrics across all
websites. For each metric, the performance improvement varies for
different webpages. Hence, the \emph{min-max} bars in this graph
show the range of improvement achieved across various webpages. The baseline is the Linux default interactive governor.

\paragraph*{Load Time}
Figure~\ref{fig:overall} (a) shows the achieved performance when fast load time is the first priority.
Under this setting, WS achieves an averaged speedup of 1.34x
but it causes significant slowdown (up to 1.26x) for some websites. By
contrast, our approach never leads to degrading performance and
delivers up to 1.92x speedup.
Overall, our approach outperforms WS with
an average speedup of 1.45x (vs 1.34x) with constantly better performance across websites.

\paragraph*{Energy Consumption}
Figure~\ref{fig:overall} (b) compares the achieved performance when we want
to minimize the energy usage to extend the battery life. In this scenario,
adaptive schemes (WS and our approach) can significantly reduce the energy consumption through
dynamically adjusting the clock frequency of the processors. Here, WS is able
to reduce the energy consumption for most websites. It achieves on average
an energy reduction of 57.6\% (up to 85\%). Once again, our approach
outperforms WS with a better averaged reduction of 63.5\% (up to 93\%). More importantly, our approach uses less energy
for all testing websites compared to the Linux default governor, while WS sometime uses more energy than necessary.
This is largely due to the fact that our approach can better utilize the webpage characteristics to determine the optimal
frequencies for CPU cores. In addition, for several webpages, WS estimating the big core gives better energy consumption,
which are actual a poor choice. These mispredictions of WS are costly in terms of energy efficiency.

\paragraph*{EDP}
Figure~\ref{fig:overall} (c) shows the achieved performance when  we would like to
minimize the EDP value, i.e. to reduce the energy consumption without
significantly increasing load time. Both adaptive schemes achieve
improvement on EDP when compared to the Linux default governor. WS delivers
on average a reduction  of 69\% (up to 84\%), but it fails to deliver
improved EDP for some websites. Unlike WS, our
approach gives constantly better EDP performance with a reduction of at
least 20\%. Overall, we achieve on average 81\% reduction (up to 95\%) of
EDP, which translates to 38\% improvement over WS on average.


%To evaluate our SVM classification model, 400
%web pages were randomly selected for training, and others for testing.
%We apply the
%Gaussian Radial Basis function (RBF) kernel in SVM for
%non-linear classification problem and employs 73 attributes
%that we have mentioned in Table~\ref{tab:selected_features}.
%The overall contribution of each selected feature in our training process
%is shown in Figure~\ref{fig:hinton}. From dark blue to light yellow,
%one color represents one type of features, and one rectangle box
%maps one feature according to the Table~\ref{tab:selected_features}
%lists. The size of rectangle represents the importance for the
%SVM prediction accuracy. For instance, as we can see from this diagram, the html tags
%\texttt{<a>}, \texttt{<div>}, \texttt{<img>}, html attributes \texttt{<href>}, \texttt{<cellspacing>},
%and \texttt{web page size}
%play the important roles in classification.
%
%There are two key factors
%that affect the accuracy of SVM based model, C and gamma.
%C controls the cost of misclassification on the training data.
%Gamma is the radial basis function-specific kernel parameter.
%Usually, a small gamma will give a low bias and high variance
%while a large gamma will give a higher bias and low variance.
%We use the R package e1071 svm.tune() function to find the
%best cost and gamma via tune the two parameters automatically.
%Finally, we get the best energy prediction by C = 100, gamma
%= 0.1, with 88\% accuracy for optimal energy
%metric. And best EDP prediction by C = 10, gamma = 0.5 with 83\% accuracy
%for optimal EDP metric.

\subsection{Compare to Oracle}
%We compare our SVM model with Oracle and webpage-aware scheduling (WS)
%mechanism on a heterogeneous system. The baseline is
%Android default interactive governor.
%As can be seen from Figure~\ref{fig:oracle}, our SVM model outperforms the baseline
%and WS for the lower is better metric.

%Although our scheme performs well compared to existing approaches, it is
%useful to know whether there is further room for improvement.
In Figure~\ref{fig:performance2oracle}, we compare our scheme to an ideal predictor
(\emph{oracle}) that always gives the optimal processor configuration. This
comparison indicates how close our approach is to the theoretically perfect
solution.
As can be seen from the diagram, our approach achieves 85\%, 90\% and 88\% of
the Oracle performance for load time, energy consumption and EDP
respectively. The performance of our approach can be further improved by
using more training webpages together with more features to better
characterize some of the web workloads and improve the prediction accuracy.


%Besides the Oracle, both SVM and WS achieve a
%significant energy reduction over the interactive baseline,
%with a (arithmetic) average \FIXME{Use geometric mean} of 65.4\%, 60.1\% and 53.3\%, respectively.
%This is because both our SVM model and WS can schedule the render process
%to the lower power processor setting. Figure~\ref{fig:oracle}(a)
%shows that our SVM model has a denser energy-reduction
%distribution and higher median than the WS. It further demonstrates
%that our scheduler has a higher energy reduction ability.
%Figure~\ref{fig:oracle}(b) compares the EDP reduction achieved by
%our approach against Oracle and WS. The best schedule, Oracle is able to
%reduce by 73.6\% for the EDP. The SVM and WS with an average of 69.4\% and 61.4\%
%aginest the baseline.

\subsection{Analysis}
\subsubsection{Optimal Configurations}
\begin{figure*}[t!]
	\centering
    \subfloat[Load time]
    {\includegraphics[width=0.28\textwidth]{figure/loadtime_distribution.pdf}}
    \hfill
	\subfloat[Energy consumption]
    {\includegraphics[width=0.28\textwidth]{figure/energy_distribution.pdf}}
    \hfill
    \subfloat[EDP]
    {\includegraphics[width=0.28\textwidth]{figure/EDP_distribution.pdf}}
    \hfill

    \caption{The distribution of the optimal processor configurations for load time (a), energy consumption (b) and EDP (c).}
    \label{fig:distribution}
    \vspace{-4mm}
\end{figure*}
Figure~\ref{fig:distribution} shows how the distribution of optimal
processor configurations changes from one optimization goal to the other. If
we want to optimize for load time, we should always run the rendering process
on the fast, big core (A15) with a frequency of at least 1.6 GHz. For this
optimization goal, nearly half of the websites benefit from using the A15 core at 1.9
GHz while others prefer to run at a lower frequency (1.6 GHz to 1.8 GHz).
The reasons that some websites benefit from a lower frequency is because of CPU throttling~\cite{cputhrottling}, i.e. the hardware will automatically
drop the frequency if the CPU becomes too hot when operating at a higher
frequency for a while. We also found that running the rendering process at 2.0 GHz (a
default setting used by most Linux performance governor) does not lead to
better load time because of frequent CPU throttlings. When optimizing for
energy consumption, around 30\% of the simple websites benefit from the
energy-efficient A7 core. Furthermore,
for those websites where the A15 core is a good choice, the optimal clock frequency is lower than the one used for load time. For EDP,
using the A7 core benefits some websites but the ideal processor operating
frequency leans towards a median value of the available frequency range. This
is not supervising as EDP is a metric to quantify the trade-off between load
time and energy consumption.

\subsubsection{Performance for each configuration}
\begin{figure*}[t]
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=0.6\textwidth]{figure/all_performance.pdf}\\
  \caption{The achieved performance for all configurations listed in Table~\ref{tab:trainingConfig}.}
  \label{fig:all_performance}
  \vspace{-3mm}
\end{figure*}


Figure~\ref {fig:all_performance} shows the performance for using each
of the processor configurations listed in Table~\ref{tab:trainingConfig} across optimization metrics.
It shows that a ``one-size-fits-all" scheme fails to deliver the
optimal performance. For example, while the A15(0.8GHz)-A7(0.4GHz)
configuration is able to reduce the energy consumption by 40\% on average, it
is not as good as our adaptive approach that gives a reduction of 63.5\%.
This is confirmed by Figure~\ref{fig:distribution} (b) that running the
A15 core at 0.8GHz only benefits 20\% of the websites. Similar results can be
found for the other two optimization metrics. This experiment shows that an
adaptive scheme significantly outperforms a fixed strategy.


\subsubsection{Prediction Accuracy}
%%We apply the
%%Gaussian Radial Basis function (RBF) kernel in SVM for
%%predicting the processor configuration problem.
%%There are two key parameters to be determined for a SVM model with the RBF
%%kernel: C and $\gamma$. C controls the cost of misclassification on the training data.
%%$\gamma$ is the radial basis function-specific kernel parameter.
%%Usually, a small $\gamma$ will give a low bias and high variance
%%while a large $\gamma$ will give a higher bias and low variance.
%%It is not known beforehand what values of these parameters
%%are best for the problem; hence, some kind of parameter search must be
%%performed. We use the R~\cite{R} package e1071 svm.tune() function to find the
%%best cost and $\gamma$  by tuning the two parameters automatically.
%%Finally, we
%%pick the pair of parameters that gives the best
%%accuracy and use it to train a
%%final model by using the whole training data set.
%%We achievea an accuracy of 82.9\%, 88\% and 85\%, respectively for
%%load time, energy and EDP metrics.
%\FIXME{This is not prediction accuracy. We should how the prediction accuracy per website for per metric.}
%In our useful processor settings,
%our approach predicts 82.9\% of the webpages without error for load time metric, they can mapped to
%the best configuration directly, and the other 17.1\% wrong predict webpages
%achieve an average of 24\% improvement for load time against the interactive governor.
%In the respect of energy and EDP, our approach still perform
%well, predicts 88\% and 85\% of webpages without error, and the other wrong predict webpages
%still achieves an average of 20.5\% and 56\% improvement than interactive governor.

Our approach gives correct predictions for
82.9\%, 88\% and 85\% of the webpages for load time, energy consumption and
EDP respectively. For those webpages that our approach does not give the best
configuration, the resulted performance is not far from the optimal, where
we still achieve a reduction of 24\%, 21\% and 56\% for load time,
energy consumption and EDP when compared to the
Linux interactive governor. The prediction accuracy can be improved through using more training examples.



\subsubsection{Breakdown of Overhead\label{sec:breakdown}}
\begin{figure}
\centering
\includegraphics[width=0.32\textwidth]{figure/overhead.pdf}
\caption{Breakdown of runtime overhead to the webpage rendering time.}
\label{fig:overhead}
\vspace{-4mm}
\end{figure}

Figure~\ref{fig:overhead} shows the breakdown of runtime overhead. Our approach has relatively low overhead with respect to the webpage rendering time, less than 4\% in total. The majority of the
time is spent on task migration (15 ms) to move the rendering process from
one processor to the other. This is expected as task migration involves
initializing the hardware context e.g. cache warmup, which can
take a few micro-seconds. The overhead of other operations, i.e. feature
extraction, making prediction and setting processor frequency, is low, which
are less than 5 ms in total. Given the benefit our approach brings,
such a low cost is acceptable.


%\FIXME{A breakdown of the overhead: feature extraction, prediction, processor configuration and task migration.}
%Our predictive model is trained offline with training
%examples, which has no impact
%on runtime cost. The overhead of using the trained model and run time scheduler
%includes extracting program features, making predictions,
%processor configuration and task migration.
%This overhead is negligible (less than 20ms in total),
%the SVM model make a prediction very quickly, less than 3ms on
%average, and the scheduler takes less than 15ms to set the processor configuration and
%make the task migration, which have been included in all experimental results, as Figure~\ref{fig:overhead} shows..

%\FIXME{We need a bar chart to show the overhead.}


\subsubsection{Feature Importance}
%During the training phase, we collect all possible website features. We then
%select a set of best features (Table~\ref{tab:selected_features}) based on
%information gain ratio.
Figure~\ref{fig:hinton} shows a Hinton diagram
illustrates some of the most important features that have an impact on the
load time, energy and EDP specific models. Here the larger the box, the more
significantly a particular feature contributes to the prediction accuracy.
The x-axis denotes the features and the y-axis denotes the SVM model. The importance is
calculated through the information gain ratio.  It can
be observed that HTML tags and attributes (e.g. \texttt{<li>},
\texttt{<img>}, \texttt{<bgcolor>}) and style rules are important when determining
the processor configurations for all optimization metrics.
Other metrics are extremely important for some optimization metrics (such as
\#DOM nodes is important for energy, and \#HTML.tag.table is important for
load time and energy) but less important for others. This diagram illustrates
the need for a distinct model for each optimization goal and how important
it is to have an automatic technique to construct such models.


\subsubsection{Adapt to Different Network Environments \label{sec:network_environment}}
\begin{figure}[t!]
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=0.4\textwidth]{figure/hinton.pdf}\\
  \vspace{-2mm}
  \caption{A Hinton diagram showing the importance of the selected web feature to the prediction accuracy. The larger the box, the more likely a feature affects the prediction accuracy of the respective model.}
  \label{fig:hinton}
  \vspace{-3mm}
\end{figure}

\begin{figure}[!t]
\begin{center}
\includegraphics[width=0.45\textwidth]{figure/differentnetwork.pdf}
\end{center}
\caption{Webpage rendering time to the time spent on downloading the contents in different network environments.}
\vspace{-3mm}
\label{fig:latency}
\end{figure}

In the previous experiments, we have isolated the network impact by
pre-downloading the webpage into a RAM disk. In practice, the device can be
used in different network environments. A natural question to ask is: which of the three
models developed in this work best suits for a particular environment? Figure~\ref{fig:latency}
shows the webpage rendering time with respect to the download time under
different network settings: 2G, 3G, 4G and WiFi (802.11). We further
breakdown each environment into two groups: poor and good. A network
environment is considered to be poor if the packet loss is greater than 30\%,
otherwise it is considered to be good. As can be seen from the diagram, the
download time dominates the total processing time in poor and good 2G network
environments. In such environments, our energy-consumption-tuned model can be
used to trade rendering performance for energy consumption without
compromising the user experience (because the network but not the processor
is the bottleneck), by moving the rendering process to run on an energy-tuned
processor at a low frequency. Our EDP-tuned model is mostly suitable for a
good 3G network environment which has a limited downloaded bandwidth.
Finally, our load-time-tuned model can be used in good 4G and Wifi
environments to satisfy the performance
requirement if load time is the first priority.  This diagram demonstrates the need of an adaptive scheme in different network environments.

%Figure~\ref{fig:latency} describes our approach's processing delay to different wireless technologies latency
%under different scenarios: Adverse/Good WiFi, Adverse/Good Mobile 2G/3G/4G network. We can observe that our approach
%delay makes up a small proportion compare to the network latency, especially under adverse network.
%So the overhead for approach is negligible in practice.
%Further more, the network latency has a significant impact on energy consumption and load time for mobile browsing.
%For example, in the adverse network, the high performance CPU has to wait a long
%time until the web contents are ready to rendering.
%In this situation,
%the high processor configuration would cost much unnecessary energy.
%There is significant room for improvement with different network latency.
%We could study the relationship between the CPU configuration and network latency,
%and find a suitable match for lower overhead.


\begin{figure}[!t]
	\centering
    \subfloat[][\#DOM nodes]{\includegraphics[width=0.24\textwidth]{figure/dom_nodes.pdf}}
    \hfill
    \subfloat[][Webpage size]{\includegraphics[width=0.24\textwidth]{figure/webpage_size.pdf}}
    \caption{The \#DOM nodes (a) and webpage size (b) for the webpages used in the experiments.}
    \vspace{-3mm}
    \label{fig:diversity}
\end{figure}

\begin{figure*}[t]
	\centering
    \subfloat[Load time]
    {\includegraphics[width=0.28\textwidth]{figure/loadtime2ws.pdf}}
    \hfill
	\subfloat[Energy reduction]
    {\includegraphics[width=0.28\textwidth]{figure/energy2ws.pdf}}
    \hfill
    \subfloat[EDP]
    {\includegraphics[width=0.28\textwidth]{figure/EDP2ws.pdf}}
    \hfill

    \caption{Achieved performance for load time (a), energy consumption (b) and EDP (c) over the Linux default policy.}
    \label{fig:overall}
    \vspace{-2mm}
\end{figure*}


\section{Experimental Setup \label{sec:setup}}

\subsection{Hardware and Software Platform}
\paragraph*{Evaluation Platform} Our evaluation platform is an Odroid XU3 mobile development board with two heterogeneous ARM processors. The board has 2 GB LPDDR3 RAM and uses a 64 GB eMMC card as storage. Table~\ref{tbl:config} gives detailed information of the hardware platform.  We chose this platform as it is a representative big.LITTLE architecture implementation. For example, the Galaxy S4 phone uses this architecture. The board runs the Linux Ubuntu 14.04 operating system. We used the on board energy sensors to measure the energy of the entire system. These sensors have been checked against external power measurement instruments and proven to be accurate in prior work~\cite{imes2015bard}. We implemented our model as an extension in Google Chromium (version 48.0) which is compiled using the gcc compiler.

\paragraph*{Webpages} We used the landing page of the top 500 hottest websites from alexa. Whenever possible, we used
the mobile version of the website for evaluation. To isolate network and disk overhead, we have downloaded and stored the
webpages in a RAM disk. We also disabled the browser's cache in the experiments.
Figure~\ref{fig:diversity} shows the number of DOM nodes and webpage sizes for the 500 websites used in our evaluation. As can be seen from this diagram, the websites range from small (only 4 DOM nodes and 40 Kilobytes) to large (over 8,000 DOM nodes and over 5 MB).

%Figure~\ref{fig:diversity} presents two key web features, \#DOM nodes and webpage size, for our predictive model.
%As can be seen from Figure~\ref{fig:diversity}(a), the webpages' \#DOM nodes range from 4 to 8852. Although 95\% of webpage
%\#DOM nodes concentrated in 50 to 4000, still exist huge diversities for most webpages.
%There is also big difference in webpage size, Figure~\ref{fig:diversity}(b) shows that the maximum (5868Kbyte)
%webpage size is 3000 times larger than minimum size.

\begin{table}[t!]
\begin{center}
\caption{Hardware platform}
\scriptsize
\label{tbl:config}
\begin{tabular}{llll}
\toprule
&big CPU & LITTLE CPU & GPU \\
\midrule
\textbf{Model} & Cortex-A15 & Cortex-A7  & Mali-T628 \\
\textbf{Core Clock} & 2.0 GHz & 1.4 GHz & 533 MHz \\
\textbf{Fore Count} & 4 & 4 & 8 \\
\bottomrule
\end{tabular}
\end{center}
\vspace{-5mm}
\end{table}
\subsection{Evaluation Methodology \label{sec:evluation_method}}

\paragraph*{Predictive Model Evaluation}
We use \emph{leave-one-out} cross-validation to evaluate
our machine learning model.
This means we remove the target webpage to be predicted
from the training example set and then build a model
based on the remaining webpages. We repeat this procedure
for each webpage in turn. It is a standard evaluation
methodology, providing an estimate of the generalization ability
of a machine-learning model in predicting \emph{unseen}
data.

\paragraph*{Alternative Approaches} We compare our approach to two
alternative approaches, a state-of-the-art web-aware scheduling
mechanism~\cite{YZhu13} (\emph{termed WS}) and the Linux interactive governor. WS uses a regression model built from the training examples to
estimate webpage load time and energy consumption under different processor
configurations. The model is used to find the best configuration by enumerating
all possible configurations.

\paragraph*{Performance Report}
We profiled each webpage under a processor configuration multiple times
and report the \emph{geometric mean} of each evaluation metric. To determine
how many runs are needed, we calculated the confidence range using a 95\%
confidence interval and make sure that  the difference between the upper and
lower confidence bounds is smaller than 5\%. We instrumented the Chromium
rendering engine to measure the load time. We excluded the time spent on
browser bootstrap and shut down. To measure the energy consumption, we have
developed a lightweight runtime to take readings from the on-board energy
sensors at a frequency of 10 samples per second. We then matched the
energy readings to the rendering process using timestamps to
calculate the energy consumption.

